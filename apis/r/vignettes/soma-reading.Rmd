---
title: "Reading from SOMA objects"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Reading from SOMA objects}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

## Overview

In this tutorial we'll learn how to read data from various SOMA objects. We will assume familiarity with SOMA objects, so it is recommended to go through the `vignette("soma-objects")` first.

A core feature of SOMA is the ability to read _subsets_ of data from disk into memory as slices. SOMA uses [Apache Arrow](https://arrow.apache.org/) as an intermediate in-memory storage. From here, the slices can be further converted into native R objects, like data frames and matrices.

```{r}
library(tiledbsoma)
```

## Example data

Load the bundled `SOMAExperiment` containing a subsetted version of the 10X genomics [PBMC dataset](https://mojaveazure.github.io/seurat-object/reference/pbmc_small.html) provided by SeuratObject. This will return a `SOMAExperiment` object. This is a small dataset that easily fits into memory, but we'll focus on operations that can easily scale to larger datasets as well.

```{r}
experiment <- load_dataset("soma-exp-pbmc-small")
```

## SOMA DataFrame

We'll start with the `obs` dataframe. Simply coercing the output of the `$read()` method will load all of the data in memory as an [Arrow Table](https://arrow.apache.org/docs/r/reference/Table.html) or data.frame.


```{r}
obs <- experiment$obs
arrow::as_arrow_table(obs$read())
```

```{r}
as.data.frame(obs$read())
```

The output of `$read()` is actually an iterator that can be used to retrieve data in chunks that are smaller than the `soma.init_buffer_bytes` parameter.  You can user the iterator's method `$read_next()` to load a chunk 
in memory.

```{r}
iterator <- obs$read()
iterator$read_next()
```

In this example the full table is relatively small and fits all in one chunk.

For bigger `SOMADataFrame`s you can check if the iteration has finished by checking the logical `$read_complete()`, and you can concatenate the rest of the chunks by using `$concat()`.

Here we demonstrate by creating a fresh new iterator.

```{r}
iterator <- obs$read()
iterator$read_complete()
```
```{r}
iterator$concat()
```

### Slicing

Slices of data can be read by passing coordinates to the `read()` method. Before we do that, let's take a look at the schema of `obs`:

```{r}
obs$schema()
```

With any SOMA object, you can only slice across an indexed column (a "dimension" in TileDB parlance). You can use `dimnames()` to retrieve the names of any SOMA object's indexed dimensions:

```{r}
obs$dimnames()
```

In this case, there is a single dimension called `soma_joinid`. From the schema above we can see this contains integers.

Let's look at a few ways to slice the dataframe.

Select a single row:

```{r}
as.data.frame(obs$read(coords = 0))
```

Select multiple, non-contiguous rows:

```{r}
as.data.frame(obs$read(coords = c(0, 2)))
```

Select multiple, contiguous rows:

```{r}
as.data.frame(obs$read(coords = 0:4))
```

### Selecting columns

As TileDB is a columnar format, it is possible to select a subset of columns to read by using the `column_names` argument:

```{r}
as.data.frame(obs$read(coords = 0:4, column_names = c("obs_id", "groups")))
```

### Filtering

In addition to slicing by coordinates you can also apply filters to the data using the `value_filter` argument. These expressions are pushed down to the TileDB engine and efficiently applied to the data on disk. Here are a few examples.

Identify all cells in the `"g1"` group:

```{r}
as.data.frame(obs$read(value_filter = "groups == 'g1'"))
```

Identify all cells in the `"g1"` or `"g2"` group:

```{r}
as.data.frame(obs$read(value_filter = "groups == 'g1' | groups == 'g2'"))
```

Altenratively, you can use the `%in%` operator:

```{r}
as.data.frame(obs$read(value_filter = "groups %in% c('g1', 'g2')"))
```

Identify all cells in the `"g1"` group with more than more than 60 features:

```{r}
as.data.frame(obs$read(value_filter = "groups == 'g1' & nFeature_RNA > 60"))
```

## SOMA SparseNDArray

For `SOMASparseNDArray`, let's consider the `X` layer containing the `"counts"` data:

```{r}
counts <- experiment$ms$get("RNA")$X$get("counts")
counts
```

Similar to `SOMADataFrame`, we can load the data into memory as an Arrow Table.

```{r}
arrow::as_arrow_table(counts$read()$tables())
```
Or as a [`Matrix::dgTMatrix`], [`Matrix::dgCMatrix`], or [`Matrix::dgRMatrix`]. Keep in mind that dgTMatrix is 
the most memory-efficient option.

```{r}
as(counts$read(), "TsparseMatrix")
```

You can also iterate by chunks. However with `SOMASparseNDArray` the method `$read()` returns a reader 
that gives you access to 2 different iterators, one for Arrow Table and one for dgTMatrix.

Let's take a look at the Arrow Table iterator:

```{r}
reader <- counts$read()
iterator <- reader$tables()
iterator$read_next()
```
Similar to the `SOMADataFrame` example the data is small enough to fit in one chunk. For bigger data
you can user `iterator$read_complete()` to check the status of iteration and `iterator$concat()`
to concatenate the rest of the chunks.

The dgTMatrix iterator works in the same way:

```{r}
reader <- counts$read()
iterator <- reader$sparse_matrix()
iterator$read_next()
```

### Slicing

Just as with a `SOMADataFrame`, we can also retrieve subsets of the data from a `SOMASparseNDArray` that can fit in memory.

Unlike `SOMADataFrame`s, `SOMASparseNDArray`s are always indexed using a zero-based offset integer on each dimension, named `soma_dim_N`. Therefore, if the array is `N`-dimensional, the `read()` method can accept a list of length `N` that specifies how to slice the array.

`SOMASparseNDArray` dimensions are always named `soma_dim_N` where `N` is the dimension number. As before you could use `schema()` or `dimnames()` to retrieve the dimension names.

```{r}
counts$schema()
```

For example, here's how to fetch the first 5 rows of the matrix:

```{r}
reader <- counts$read(coords = list(soma_dim_0 = 0:4))
as(reader, "TsparseMatrix")
```
